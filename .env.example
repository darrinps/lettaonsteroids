# =============================================================================
# Letta vs Mem0 Benchmark Configuration (EXAMPLE)
# =============================================================================
# This is an example configuration file. Copy this to .env and replace
# placeholder values with your actual API keys and configuration.
#
# Quick setup:
#   1. Copy this file: cp .env.example .env
#   2. Replace sk-REPLACE_ME with your OpenAI API key
#   3. Update MEM0_API_KEY if using Mem0 cloud API
#   4. Adjust other settings as needed

# -----------------------------------------------------------------------------
# API Keys (REQUIRED)
# -----------------------------------------------------------------------------

# OpenAI API key - Required for:
#   - LLM completions (backend responses)
#   - Embedding generation (similarity calculations)
#   - Mem0's LLM post-processing (formatting responses)
# Get your key from: https://platform.openai.com/api-keys
OPENAI_API_KEY=sk-REPLACE_ME

# -----------------------------------------------------------------------------
# Backend Server URLs
# -----------------------------------------------------------------------------

# Letta server base URL
# Default: http://localhost:8283 (local server)
# For remote: http://your-server-ip:8283
LETTA_BASE_URL=http://localhost:8283

# Mem0 server base URL
# Default: http://localhost:3000 (local server - RECOMMENDED for fair benchmarks)
# For Mem0 cloud API: https://api.mem0.ai (adds 100-400ms network latency per call)
# WARNING: Using cloud API will significantly inflate latency metrics in benchmarks
MEM0_BASE_URL=http://localhost:3000

# Mem0 API key (only required if using Mem0 cloud API)
# Get your key from: https://app.mem0.ai/
# Leave empty if running local Mem0 server
MEM0_API_KEY=

# -----------------------------------------------------------------------------
# Model Configuration
# -----------------------------------------------------------------------------

# Default LLM model for agent responses
# Examples: gpt-4o-mini, gpt-4o, gpt-3.5-turbo
# Note: Letta expects format "openai/model-name", mem0 uses "model-name"
DEFAULT_LLM_MODEL=openai/gpt-4o-mini

# Default embedding model for semantic similarity
# Examples: text-embedding-3-small, text-embedding-3-large, text-embedding-ada-002
# Used for calculating mean_similarity scores
DEFAULT_EMBEDDING_MODEL=openai/text-embedding-3-small

# -----------------------------------------------------------------------------
# Benchmark Configuration (Optional - can override via CLI)
# -----------------------------------------------------------------------------

# Default number of conversation turns per scenario
# Typical range: 3-20 turns
BENCH_DEFAULT_TURNS=12

# Number of test sessions to run for statistical averaging
# Higher values reduce variance but increase runtime
# Recommended: 1 for quick tests, 3+ for production benchmarks
BENCH_SESSIONS=3

# Noise ratio for degradation resilience tests (0.0 - 1.0)
# 0.0 = no noise (clean input)
# 0.25 = 25% of words scrambled
# Higher values test robustness to noisy/ambiguous input
BENCH_NOISE_RATIO=0.25
